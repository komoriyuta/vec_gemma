{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2d74aa0",
   "metadata": {},
   "source": [
    "# Training Notebook\n",
    "\n",
    "この Notebook は、もともとの `train.py` のコードを Notebook 用にセル分割したものです。以下の各セルを順次実行することで、学習プロセスを開始できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c578e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yut/sail-develop/vec_gemma/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from datasets import disable_progress_bars\n",
    "disable_progress_bars()\n",
    "from datasets import load_dataset\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from schedulefree import RAdamScheduleFree\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from gemma.config import GemmaConfig, get_model_config\n",
    "from gemma.model import GemmaForCausalLM\n",
    "from VAEs.LinearVAE import LinearVAE\n",
    "from VAEs.VAE import VAE\n",
    "from VAEs.Perceptron import Perceptron\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d197ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    def __init__(self):\n",
    "        # データ設定\n",
    "        self.batch_size = 4\n",
    "        self.max_seq_len = 256\n",
    "        self.num_workers = 4\n",
    "        \n",
    "        # 最適化設定\n",
    "        self.lr = 1e-4\n",
    "        self.num_epochs = 10\n",
    "        self.grad_accum_steps = 4\n",
    "        self.beta_init = 0.00\n",
    "        self.beta_max = 0\n",
    "        self.beta_step = 1e-6\n",
    "        self.crop_lambda = 0.2\n",
    "\n",
    "        # モデル設定\n",
    "        self.bert_model_name = \"cl-nagoya/ruri-large\"\n",
    "        self.gemma_model_size = \"2b-v2\"\n",
    "        self.vae_hidden_dim = 512\n",
    "        self.vae_latent_dim = 128\n",
    "        \n",
    "        # 生成設定\n",
    "        self.sample_interval = 1000\n",
    "        self.num_samples = 3\n",
    "        self.max_gen_length = 100\n",
    "        self.generation_temp = 0.1\n",
    "        self.generation_top_p = 0.2\n",
    "        self.generation_top_k = 2\n",
    "        \n",
    "        self.ckpt_interval = 5000\n",
    "        # パス設定\n",
    "        self.log_dir = f\"./logs/{datetime.datetime.now()}/\"\n",
    "        self.checkpoint_dir = \"./checkpoints\"\n",
    "        self.dataset_path = \"AhmedSSabir/Japanese-wiki-dump-sentence-dataset\"\n",
    "        \n",
    "        # 初期化\n",
    "        self._setup_directories()\n",
    "        \n",
    "    def _setup_directories(self):\n",
    "        Path(self.log_dir).mkdir(parents=True, exist_ok=True)\n",
    "        Path(self.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def setup_logging(log_dir):\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(os.path.join(log_dir, \"training.log\")),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_dataset(config):\n",
    "    def collate_fn(batch):\n",
    "        return [item['text'] for item in batch]\n",
    "    \n",
    "    dataset = load_dataset(config.dataset_path, cache_dir=\"./.datasets\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset['train'].with_format(\"torch\"),\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def initialize_models(config, device):\n",
    "    # BERTモデル\n",
    "    bert_model = SentenceTransformer(config.bert_model_name)\n",
    "    bert_model.requires_grad_(False)\n",
    "    bert_model = bert_model.to(device)\n",
    "    \n",
    "    # Gemmaモデル\n",
    "    snapshot_dir = snapshot_download(repo_id='google/gemma-2-2b-jpn-it-pytorch')\n",
    "\n",
    "    # Ensure that the tokenizer is present\n",
    "    tokenizer_path = os.path.join(snapshot_dir, 'tokenizer.model')\n",
    "    assert os.path.isfile(tokenizer_path), 'Tokenizer not found!'\n",
    "\n",
    "    # Ensure that the checkpoint is present\n",
    "    ckpt_path = os.path.join(snapshot_dir, f'model.ckpt')\n",
    "    assert os.path.isfile(ckpt_path), 'PyTorch checkpoint not found!'\n",
    "    \n",
    "\n",
    "    gemma_model_config = get_model_config(\"2b-v2\")\n",
    "    gemma_model_config.tokenizer = tokenizer_path\n",
    "    \n",
    "    # Instantiate the model and load the weights.\n",
    "    torch.set_default_dtype(gemma_model_config.get_dtype())\n",
    "    gemma_model = GemmaForCausalLM(gemma_model_config)\n",
    "    gemma_model.requires_grad_(False)\n",
    "    gemma_model.load_weights(ckpt_path)\n",
    "    gemma_model = gemma_model.to(device).eval()\n",
    "    \n",
    "    # VAEモデル\n",
    "    vae_model = Perceptron(\n",
    "        bert_model.get_sentence_embedding_dimension(),\n",
    "        gemma_model.config.hidden_size,\n",
    "        hidden_dim=config.vae_hidden_dim,\n",
    "        latent_dim=config.vae_latent_dim\n",
    "    ).to(device)\n",
    "    \n",
    "    return bert_model, gemma_model, vae_model\n",
    "\n",
    "\n",
    "def generate_and_log_samples(vae_model, bert_model, gemma_model, device, writer, global_step, config):\n",
    "    vae_model.eval()\n",
    "    sample_texts = [\n",
    "        \"人工知能の未来について\",\n",
    "        \"量子コンピュータの可能性\",\n",
    "        \"ディープラーニングの応用分野\",\n",
    "        \"自然言語処理の最新動向\",\n",
    "        \"ロボット工学の進化\",\n",
    "        \"一時期所長となる。\",\n",
    "        \"京都府京都市に生まれる。\",\n",
    "        \"卒業後は文章を書く仕事がしたいと1994年に報知新聞社にスポーツ記者として勤務し、高校野球やゴルフを取材する。\",\n",
    "        \"その後、全てをリセットするためにタンザニア・ダルエスサラーム大学に留学し、スワヒリ語科で学ぶ。\",\n",
    "        \"29歳の時に新人賞の最終候補に残るが、その後結婚し、出産したことで小説を書く余裕を無くしてしまう。\",\n",
    "        \"本形式は、192形を改称して生まれた形式である。\",\n",
    "        \"ただし、現実にはこの変更を受けたのは数両程度である。\"\n",
    "    ]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prep_texts = [\"文章: \" + text for text in sample_texts]\n",
    "        \n",
    "        # BERTで埋め込みを取得\n",
    "        bert_embeddings = bert_model.encode(\n",
    "            prep_texts, \n",
    "            convert_to_tensor=True,\n",
    "            device=device,\n",
    "            show_progress_bar=False\n",
    "        ).to(torch.bfloat16)\n",
    "        \n",
    "        # VAEで埋め込みを変換\n",
    "        vae_output, _, _ = vae_model(bert_embeddings)\n",
    "        \n",
    "        # Gemmaでテキスト生成\n",
    "        generated_texts = []\n",
    "        for i in range(len(sample_texts)):\n",
    "            try:\n",
    "                embedding = vae_output[i].unsqueeze(0).unsqueeze(0)\n",
    "                generated = gemma_model.generate_with_initial_embedding(\n",
    "                    initial_embedding=embedding,\n",
    "                    device=device,\n",
    "                    output_len=config.max_gen_length,\n",
    "                    temperature=config.generation_temp,\n",
    "                    top_p=config.generation_top_p,\n",
    "                    top_k=config.generation_top_k,\n",
    "                    instructions=(\"<start_of_turn>user\\n \\\"\", \"\\\"\\nこれをそのままの意味で出力してください。<end_of_turn>\\n<start_of_turn>model\\n\")\n",
    "                )\n",
    "                generated_texts.append(generated[0])\n",
    "            except Exception as e:\n",
    "                generated_texts.append(f\"生成エラー: {str(e)}\")\n",
    "        \n",
    "        # ログに記録\n",
    "        log_text = \"\\n\\n\".join([\n",
    "            f\"入力: {sample_texts[i]}\\n生成結果: {generated_texts[i]}\" \n",
    "            for i in range(len(sample_texts))\n",
    "        ])\n",
    "        \n",
    "        writer.add_text(\"生成サンプル\", log_text, global_step)\n",
    "        logging.info(f\"\\n=== ステップ {global_step} の生成サンプル ===\\n{log_text}\\n\")\n",
    "    \n",
    "    vae_model.train()\n",
    "\n",
    "\n",
    "def train(config, vae_model, bert_model, gemma_model, optimizer, device, start_epoch=0, initial_beta=0.1):\n",
    "    writer = SummaryWriter(config.log_dir)\n",
    "    setup_logging(config.log_dir)\n",
    "    \n",
    "    instructions = [\n",
    "        (\"<start_of_turn>user\\\"\", \"\\\"\\nこれを、そのままの意味で出力してください<end_of_turn><start_of_turn>model\\n\"),\n",
    "    ]\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    beta = initial_beta\n",
    "    optimizer.train()\n",
    "\n",
    "    for epoch in range(start_epoch, config.num_epochs):\n",
    "        logging.info(f\"エポック {epoch+1}/{config.num_epochs}\")\n",
    "        train_loader = prepare_dataset(config)\n",
    "        total_steps = len(train_loader)\n",
    "        progress_bar = tqdm(\n",
    "            train_loader,\n",
    "            total=total_steps,\n",
    "            desc=f\"エポック {epoch+1}/{config.num_epochs}\",\n",
    "            bar_format=\"{l_bar}{bar:20}{r_bar}{bar:-10b}\",\n",
    "            dynamic_ncols=True\n",
    "        )\n",
    "        for step, batch_texts in enumerate(progress_bar):\n",
    "            with torch.no_grad():\n",
    "                rep_texts = [\"文章: \" + text for text in batch_texts]\n",
    "                bert_embeddings = bert_model.encode(\n",
    "                    rep_texts, \n",
    "                    convert_to_tensor=True,\n",
    "                    device=device,\n",
    "                    show_progress_bar=False\n",
    "                ).to(torch.bfloat16)\n",
    "            \n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                vae_output, mu, logvar = vae_model(bert_embeddings)\n",
    "                \n",
    "                kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "                kl_div_per_batch = kl_div / bert_embeddings.size(0)\n",
    "                kl_div = torch.maximum(\n",
    "                    kl_div_per_batch,\n",
    "                    torch.tensor(config.crop_lambda, device=kl_div.device, dtype=kl_div.dtype)\n",
    "                )\n",
    "                \n",
    "                recon_loss = gemma_model.forward_teacher_forcing(\n",
    "                    vae_output, \n",
    "                    batch_texts,\n",
    "                    max_seq_len=config.max_seq_len,\n",
    "                    instructions=instructions[random.randint(0, len(instructions)-1)],\n",
    "                )\n",
    "                \n",
    "                loss = recon_loss + beta * kl_div\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % config.grad_accum_steps == 0:\n",
    "                optimizer.step()\n",
    "            \n",
    "            writer.add_scalar(\"損失/訓練\", loss.item(), epoch*len(train_loader)+step)\n",
    "            writer.add_scalar(\"損失/再構成\", recon_loss.item(), epoch*len(train_loader)+step)\n",
    "            writer.add_scalar(\"損失/KL\", kl_div.item(), epoch*len(train_loader)+step)\n",
    "            writer.add_scalar(\"Beta\", beta, epoch*len(train_loader)+step)\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"recon\": f\"{recon_loss.item():.4f}\",\n",
    "                \"kl\": f\"{kl_div.item():.4f}\",\n",
    "                \"beta\": f\"{beta:.4f}\"\n",
    "            })\n",
    "            optimizer.eval()\n",
    "\n",
    "            if step % config.sample_interval == 0:\n",
    "                generate_and_log_samples(\n",
    "                    vae_model=vae_model,\n",
    "                    bert_model=bert_model,\n",
    "                    gemma_model=gemma_model,\n",
    "                    device=device,\n",
    "                    writer=writer,\n",
    "                    global_step=epoch*len(train_loader)+step,\n",
    "                    config=config,\n",
    "                )\n",
    "            if step % config.ckpt_interval == 0:\n",
    "                checkpoint = {\n",
    "                    \"epoch\": epoch-1,\n",
    "                    \"model_state\": vae_model.state_dict(),\n",
    "                    \"optimizer_state\": optimizer.state_dict(),\n",
    "                    \"loss\": loss.item(),\n",
    "                    \"beta\": beta,\n",
    "                    \"settings\": config.__dict__\n",
    "                }\n",
    "                torch.save(checkpoint, os.path.join(config.checkpoint_dir, f\"checkpoint_epoch_{epoch+1}_step_{datetime.datetime.now()}_{step}.pt\"))\n",
    "                torch.save(vae_model.state_dict(), os.path.join(config.checkpoint_dir, \"latest_model.pt\"))\n",
    "            optimizer.train()\n",
    "            beta = min(config.beta_max, beta + config.beta_step)\n",
    "        \n",
    "        generate_and_log_samples(\n",
    "            vae_model=vae_model,\n",
    "            bert_model=bert_model,\n",
    "            gemma_model=gemma_model,\n",
    "            device=device,\n",
    "            writer=writer,\n",
    "            global_step=(epoch+1)*len(train_loader),\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": vae_model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"loss\": loss.item(),\n",
    "            \"beta\": beta,\n",
    "            \"settings\": config.__dict__\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(config.checkpoint_dir, f\"checkpoint_epoch_{epoch+1}_{datetime.datetime.now()}.pt\"))\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            torch.save(vae_model.state_dict(), os.path.join(config.checkpoint_dir, f\"best_model{datetime.datetime.now()}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b7c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 86480.49it/s]\n",
      "/home/yut/sail-develop/vec_gemma/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1132: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:308.)\n",
      "  return self._apply(lambda t: t.type(dst_type))\n"
     ]
    }
   ],
   "source": [
    "# --- 初期化＆チェックポイントの読み込み（必要に応じて） ---\n",
    "\n",
    "config = TrainingConfig()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "bert_model, gemma_model, vae_model = initialize_models(config, device)\n",
    "vae_model.type(torch.bfloat16)\n",
    "gemma_model.type(torch.bfloat16)\n",
    "optimizer = torch.optim.RAdam(vae_model.parameters(), lr=config.lr)\n",
    "\n",
    "# チェックポイントから再開したい場合は、以下 resume にパスを設定してください。なければ None のままでOK\n",
    "resume = None  # 例: \"./checkpoints/your_checkpoint.pt\"\n",
    "if resume:\n",
    "    checkpoint = torch.load(resume, map_location=device)\n",
    "    vae_model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    beta = checkpoint[\"beta\"]\n",
    "    if \"settings\" in checkpoint:\n",
    "        config.__dict__.update(checkpoint[\"settings\"])\n",
    "    logging.info(f\"Resuming training from epoch {start_epoch}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    beta = config.beta_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa00f46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1552734375\n",
      "fc1.weight 25.25\n",
      "fc1.bias 0.9765625\n",
      "fc2.weight 8.6875\n",
      "fc2.bias 2.453125\n"
     ]
    }
   ],
   "source": [
    "text = \"あああああああ\"\n",
    "bert_emb = bert_model.encode([text], convert_to_tensor=True, device=device).to(torch.bfloat16)\n",
    "vae_output, _, _ = vae_model(bert_emb)\n",
    "gemma_model.train()\n",
    "\n",
    "loss = gemma_model.forward_teacher_forcing(\n",
    "    vae_output, [text], max_seq_len=config.max_seq_len,\n",
    "    instructions=(\"<start_of_turn>user\\n \\\"\", \"\\\"\\nこれをそのままの意味で出力してください。<end_of_turn>\\n<start_of_turn>model\\n\")\n",
    ")\n",
    "print(loss.item())\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 例: loss の計算が終わった後\n",
    "dot = make_dot(loss, params=dict(vae_model.named_parameters()))\n",
    "dot.render(\"loss_graph\", format=\"svg\")  # loss_graph.png として保存される\n",
    "\n",
    "with torch.autograd.set_detect_anomaly(True):\n",
    "    loss.backward()\n",
    "    for name, param in vae_model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            print(name, param.grad.norm().item())\n",
    "        else:\n",
    "            print(name, \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- トレーニング開始 ---\n",
    "train(\n",
    "    config=config,\n",
    "    vae_model=vae_model,\n",
    "    bert_model=bert_model,\n",
    "    gemma_model=gemma_model,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    start_epoch=start_epoch,\n",
    "    initial_beta=beta\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1913f6",
   "metadata": {},
   "source": [
    "学習が開始されました。ログや TensorBoard を確認してください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
